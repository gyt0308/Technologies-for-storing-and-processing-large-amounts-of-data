{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Task2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset from hdfs\n",
    "df=spark.read.option(\"header\", True).csv('hdfs://localhost:9000/input/india-news-headlines.csv')\n",
    "# De-weight the entire DataFrame\n",
    "df_distinct = df.dropDuplicates()\n",
    "# Convert to rdd\n",
    "news_rdd = df_distinct.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The top 10 years with the most news releases were counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Year|Count|\n",
      "+----+-----+\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "|2001|    1|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use rdd map method to convert dataset\n",
    "news_year_rdd = news_rdd.map(lambda row: (row[0][:4],1))\n",
    "# Converts an RDD to a DataFrame and specifies the column names\n",
    "news_year_df = spark.createDataFrame(news_year_rdd, [\"Year\", \"Count\"])\n",
    "# Show DataFrame\n",
    "news_year_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|Year| Count|\n",
      "+----+------+\n",
      "|2016|254168|\n",
      "|2018|253294|\n",
      "|2014|253240|\n",
      "|2013|253098|\n",
      "|2015|252966|\n",
      "|2012|252915|\n",
      "|2017|251375|\n",
      "|2011|240784|\n",
      "|2009|203990|\n",
      "|2020|182087|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_year_count_rdd=news_year_rdd.reduceByKey(lambda a,b:a+b)\n",
    "# Sorting RDDs by sortBy and descending by count\n",
    "news_year_count_rdd = news_year_count_rdd.sortBy(lambda x: x[1], ascending=False).take(10)\n",
    "# Converts an RDD to a DataFrame and specifies the column names\n",
    "news_year_top_10 = spark.createDataFrame(news_year_count_rdd, [\"Year\", \"Count\"])\n",
    "# Show DataFrame\n",
    "news_year_top_10.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Specify the top 10 word frequencies in a news category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a list of deactivated words\n",
    "stopwords = set([\"the\", \"is\", \"in\", \"at\", \"which\", \"on\", \"and\", \"a\", \"to\", \"of\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|category|        word|\n",
      "+--------+------------+\n",
      "| history|        1930|\n",
      "| history|    Hamilton|\n",
      "| history|     British|\n",
      "| history|      Empire|\n",
      "| history|       Games|\n",
      "| history|        1958|\n",
      "| history|     Cardiff|\n",
      "| history|     British|\n",
      "| history|      Empire|\n",
      "| history|Commonwealth|\n",
      "+--------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #Filtering specific categories of data\n",
    "filter_category = \"history\"   \n",
    "filter_category_rdd = news_rdd.filter(lambda row: row[1] == filter_category)\n",
    "# Extracting words from headings using flatMap\n",
    "flatMap_rdd = filter_category_rdd.flatMap(lambda row: [(row[1], word) for word in row[2].split()])\n",
    "# Filter out stop words\n",
    "flatMap_rdd = flatMap_rdd.filter(lambda x: x[1].lower() not in stopwords)\n",
    "# Converts an RDD to a DataFrame and specifies the column names\n",
    "flatMap_df = spark.createDataFrame(flatMap_rdd, [\"category\", \"word\"])\n",
    "# Show DataFrame\n",
    "flatMap_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|       Games|   19|\n",
      "|Commonwealth|   15|\n",
      "|     British|   10|\n",
      "|      Empire|    8|\n",
      "|     Thunder|    4|\n",
      "|        Down|    4|\n",
      "|       Under|    4|\n",
      "|   Wimbledon|    4|\n",
      "|        clay|    3|\n",
      "|       Open:|    3|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the word frequency of each word\n",
    "word_count_rdd = flatMap_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b)\n",
    "# Get the top 10 words with the most occurrences\n",
    "top_10_words = word_count_rdd.sortBy(lambda x: x[1], ascending=False).take(10)\n",
    "# Converts an RDD to a DataFrame and specifies the column names\n",
    "top_10_words_df = spark.createDataFrame(top_10_words, [\"word\", \"count\"])\n",
    "# Show DataFrame\n",
    "top_10_words_df.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
